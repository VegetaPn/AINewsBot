
在AI领域的最新进展中，诸如GPT-3这类大语言模型 (LLM) 已经显著推进了自然语言处理的边界。这些模型不仅能够创造出语法正确的文本，更在零样本 (Zero-shot) 和少样本 (Few-shot) 的应用场景中表现出令人瞩目的灵活性和适应能力。然而，将这些模型商业化依然面临不少挑战，诸如解释性和伦理问题等。尽管面对这些挑战，公司如OpenAI与Microsoft正积极探索解决方案，努力推动AI技术的广泛商业应用。


2024年4月29日

[AINews] 宁静周末的简报
========================


> 欢迎来到 AI 新闻！这是一个即将推出的服务的最小可行产品 (MVP)，它能梳理来自各大 AI 社区 Discord、Twitter、Reddit 的热议话题并作出汇总，帮助您轻松了解最新动态，无需感到信息超载。立即在[这里](https://buttondown.email/ainews/)注册，我们正式推出时您将能体验到完整服务🔜


---


> 人工智能新闻，2024年4月26日至2024年4月29日。为您整理了7个Reddit子论坛和[**373**
> 位Twitter用户](https://twitter.com/i/lists/1585430245762441216?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)
> 同时还有
> **28** 
> 个Discord服务器 (
> **416** 
> 个频道，及
> **10824** 
> 条讨论信息)。您通过我们的整理，预计可以节省
> **1197分钟** 
> 的阅读时间。
> 

最近，人们热议[加州议案 SB-1047](https://www.reddit.com/r/LocalLLaMA/comments/1cfizbb/california_sb1047_seems_like_it_could_impact_open/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)，关注其对开放平台的可能影响。同时，[gpt2-chatbot](https://twitter.com/phill__1/status/1784964135920235000?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend) 在lmsys上的功能展示，以及[Llama-3-8B 的扩容至100万Token环境](https://x.com/markatgradient/status/1785032103429865748?s=46&t=90xQ8sGy63D2OtiaoGJuww&utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)也受到关注，但没有其他显著新闻头条。同时，你也可以关注[WebSim/WorldSim](https://www.latent.space/p/sim-ai?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)播客，该播客由Nous Research在解决安全问题后即将重新推出。


**目录**


* [AI Reddit 摘要](#ai-reddit-recap)
* [AI Twitter 摘要](#ai-twitter-recap)
* [AI Discord 摘要](#ai-discord-recap)
* [第一部分：Discord 高级概览](#part-1-high-level-discord-summaries) 
	+ [Unsloth AI (Daniel Han) Discord](#unsloth-ai-daniel-han-discord)
	+ [CUDA MODE Discord](#cuda-mode-discord)
	+ [Perplexity AI Discord](#perplexity-ai-discord)
	+ [Stability.ai (Stable Diffusion) Discord](#stabilityai-stable-diffusion-discord)
	+ [LM Studio Discord](#lm-studio-discord)
	+ [Nous Research AI Discord](#nous-research-ai-discord)
	+ [HuggingFace Discord](#huggingface-discord)
	+ [OpenAI Discord](#openai-discord)
	+ [Eleuther Discord](#eleuther-discord)
	+ [OpenRouter (Alex Atallah) Discord](#openrouter-alex-atallah-discord)
	+ [OpenAccess AI Collective (axolotl) Discord](#openaccess-ai-collective-axolotl-discord)
	+ [Modular (Mojo 🔥) Discord](#modular-mojo-discord)
	+ [LlamaIndex Discord](#llamaindex-discord)
	+ [OpenInterpreter Discord](#openinterpreter-discord)
	+ [Latent Space Discord](#latent-space-discord)
	+ [LAION Discord](#laion-discord)
	+ [Cohere Discord](#cohere-discord)
	+ [tinygrad (George Hotz) Discord](#tinygrad-george-hotz-discord)
	+ [Interconnects (Nathan Lambert) Discord](#interconnects-nathan-lambert-discord)
	+ [LangChain AI Discord](#langchain-ai-discord)
	+ [Mozilla AI Discord](#mozilla-ai-discord)
	+ [AI Stack Developers (Yoko Li) Discord](#ai-stack-devs-yoko-li-discord)
	+ [DiscoResearch Discord](#discoresearch-discord)
	+ [Alignment Lab AI Discord](#alignment-lab-ai-discord)
	+ [Skunkworks AI Discord](#skunkworks-ai-discord)
	+ [LLM Performance Enthusiasts AI Discord](#llm-perf-enthusiasts-ai-discord)
	+ [Datasette - LLM (@SimonW) Discord](#datasette-llm-simonw-discord)
* [第二部分：按频道详细总结和链接](#part-2-detailed-by-channel-summaries-and-links)


在人工智能领域，大语言模型（LLM）如OpenAI的GPT-4和Google的Gopher通过学习庞大的词汇数据库，展示了它们解决复杂语言问题的潜力。这些模型依托先进的深度神经网络技术，达到了处理近似人类反应和回答的程度。然而，训练这些模型的成本极高，不仅经济负担重，还有环境损害，因为需要消耗大量电力和计算资源，进而产生大量的碳排放。此外，生成式 AI（Generative AI）在图像生成领域的应用，如DALL-E和Stability.ai旗下的LlaMa，标志着AI技术的新进展，尽管如此，使机器具备创造力的路径仍然充满了挑战。


---


AI Reddit 社区简报
===============


> 在 r/LocalLlama、r/machinelearning、r/openai、r/stablediffusion、r/ArtificialInteligence、r/LLMDevs、r/Singularity 等社区中，评论爬取功能现已启用，但仍需大量改进！


**AI 模型与能力的前沿进展**


* **Yann LeCun 预测未来将用 AR 界面的 AI 助手取代智能手机**
 : Yann LeCun 在 /r/singularity 上表示，未来10到15年我们将通过 [AR 眼镜和手镯](https://www.reddit.com/r/singularity/comments/1cfr9j4/yann_lecun_says_in_10_years_we_wont_have/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)，而不是智能手机，与智能助手进行交互。
* **基于 Llama-3 的 Dolphin-2.9 新模型发布**
 : 在 /r/LocalLLaMA 社区中, [人们发布了基于 Llama-3 的 Dolphin-2.9 新模型，该模型可能改善了前一版本的质量问题](https://www.reddit.com/r/LocalLLaMA/comments/1cf3k1d/anyone_tried_new_dolphin29llama38b256k/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)。
* **PixArt Sigma 模型仅用 0.6B 参数实现了 Stable Diffusion 3.0 的性能水平**
 : 在 /r/singularity 论坛上，[PixArt Sigma 模型仅借助 0.6B 参数达到了 Stable Diffusion 3.0 的性能水平，完全响应提示且可本地运行](https://www.reddit.com/r/singularity/comments/1cfacll/pixart_sigma_is_the_first_model_with_complete/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)。
* **Transformer 能用无意义的填充 Token 完成算法任务**
 : 在 /r/LocalLLaMA 和 /r/MachineLearning 中，研究表明 [Transformer 能以 ‘......’ 等无意义填充 Token 代替思考过程来解决算法问题，这要求特定的密集监督以达到收敛](https://www.reddit.com/r/LocalLLaMA/comments/1cf2w5a/transformers_can_use_meaningless_filler_tokens_eg/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)。


**人工智能 (Artificial Intelligence) 的应用**


* **AI生成的餐厅评论能够通过图灵测试**
 : 在 /r/MachineLearning 和 /r/singularity 中，有研究显示
 [AI生成的餐厅评论能够通过图灵测试，并且能够误导人类和AI检测系统](https://www.reddit.com/r/MachineLearning/comments/1cflzkmq/a_new_study_finds_that_aigenerated_restaurant/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)
 。
* **Uber 利用图算法和学习的嵌入技术来预测预计到达时间**
 : 在 /r/MachineLearning 中被分享
 [Uber 结合图算法和学习的嵌入技术，采取双层策略预测预计到达时间 (ETA)](https://www.reddit.com/r/MachineLearning/comments/1cfd15u/research_a_visual_deep_dive_into_ubers_machine/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)
 。
* **可口可乐与微软宣布五年AI合作**
 : 在 /r/singularity 中公布
 [可口可乐公司与微软开启五年合作，旨在推动云计算和生成式AI (Generative AI)的发展](https://www.reddit.com/r/singularity/comments/1cf3a6r/the_cocacola_company_and_microsoft_announce/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)
 。


**部署与优化 AI 模型**


- **Llama-3 70B 模型能在 4GB GPU 上借助 AirLLM 运行**
  : 在 /r/LocalLLaMA 的讨论中显示，[Llama-3 70B 模型可以在单个 4GB GPU 上通过 AirLLM 的优化技术运行，无需进行量化或压缩，但其运行速度较慢](https://www.reddit.com/r/LocalLLaMA/comments/1cf42vc/run_the_strongest_opensource_llm_model_llama3_70b/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)。

- **Mistral.rs 是个高速的大语言模型 (LLM) 推理平台**  
  : 如 /r/singularity 所述，[Mistral.rs 是一个支持量化、设备兼容并与 OpenAI API 兼容的高速大语言模型 (LLM) 推理平台](https://www.reddit.com/r/singularity/comments/1cfsiuy/mistralrs_a_lightningfast_llm_inference_platform/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)。

- **大语言模型 (LLM) 从原型到生产的挑战**
  : /r/MachineLearning 的一项调查发现，[仅有 5% 的大语言模型 (LLM) 能成功从原型阶段过渡到生产阶段，特别是在企业设置中面临多重挑战](https://www.reddit.com/r/MachineLearning/comments/1cf178i/d_what_are_the_most_common_and_significant/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)。

- **对比 EXL2 与 GGUF 在 Llama 模型上的量化效果**  
  : 在 /r/LocalLLaMA 的讨论中，[对 Llama-3 进行的 EXL2 量化与最新的 GGUF 量化在模型大小与困惑度方面表现相当，但相比全精度，Llama-3 与 Llama-2 在量化后性能有更多的衰减](https://www.reddit.com/r/LocalLLaMA/comments/1cfbadc/result_llama_3_exl2_quant_quality_compared_to/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)。


**挑战与困难**


* **埃里克·施密特对AI智能体使用其独有语言交流发出警告**
 : 在 /r/singularity 论坛中，埃里克·施密特指出，
 [一旦AI智能体开始使用我们无法理解的语言进行交流，我们就应该断开电脑电源。这种情况在2017年Facebook的聊天机器人上已经出现过](https://www.reddit.com/r/singularity/comments/1cfqknmm/eric_schmidt_the_point_at_which_ai_agents_can/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)
 。
* **OpenAI因忽视计费上限而向用户过高收费**
 : 在 /r/OpenAI 论坛中，有用户反映，
 [OpenAI没有遵守设定的计费上限，向他们收取了过高的费用，这可能引发一场集体诉讼](https://www.reddit.com/r/OpenAI/comments/1cfld2h/annoyed_because_openai_didnt_respect_my_billing/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)
 。
* **加利福尼亚法案SB-1047可能对开源AI造成影响**
 : 在 /r/StableDiffusion 论坛中，人们担忧，
 [加利福尼亚法案SB-1047一旦通过，可能对开源AI的发展产生负面影响](https://www.reddit.com/r/LocalLLaMA/comments/1cfizbb/california_sb1047_seems_like_it_could_impact_open/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)
 。





AI 推特精选
===========


> Claude 3 Opus负责的所有总结，均选自四次尝试中的最佳效果。我们目前正与Haiku合作，致力于聚类分析和流程工程研究。


**Prompt工程的技术与应用**


* **推理与多步骤问题求解**
  :
  [@cwolferesearch](https://twitter.com/cwolferesearch/status/1784992130777137362?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)
  最近介绍了在推理任务上的提示工程研究，包括
  **在零样本情况下使用链式推理（CoT）方式、根据问题复杂度选取示例、逐步精化推理过程及将复杂任务细分为多个子任务**
  。
* **工具使用与 API 集成**
  :
  [@cwolferesearch](https://twitter.com/cwolferesearch/status/1784992130777137362?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)
  突出了
  **教会大语言模型（LLM）如何应用外部工具和 API 的研究**
  ，比如利用基于文本的 API、包含工具调用的自然语言程序，以及在隔离环境中执行代码。
* **优化上下文窗口的使用**
  :
  [@cwolferesearch](https://twitter.com/cwolferesearch/status/1784992130777137362?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)
  讨论了上下文窗口特性的影响，如
  **无关上下文带来的消极影响、对提示文本首尾的注意力偏向，以及如何挑选出最佳的少样本示例**
  。
* **提升大语言模型辅助写作**
  :
  [@cwolferesearch](https://twitter.com/cwolferesearch/status/1784992130777137362?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)
  讲述了提高大语言模型写作能力的技术，包括
  **生成大纲与迭代填写、利用小型大语言模型产生引导性刺激、以及在概括性总结中逐步提高信息浓缩度**
  。


**大语言模型中的新兴能力与规模化法则**


* **预训练损失与模型能力的新发现**
  :
  [@_jasonwei](https://twitter.com/_jasonwei/status/1784990066609414556?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend) 
  论述了一篇分析预训练损失与模型新能力的论文，展示了
  **在某些基准测试中存在线性关联以及在特定损失阈值处出现特定行为** 
  。这表明预训练损失或许是比计算力更佳的模型比较指标。
* **函数逼近的潜在上限探讨**
  :
  [@jxmnop](https://twitter.com/jxmnop/status/1784696357892063565?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend) 
  分享了论文见解，指出
  **即使架构差异显著，不同系统在相同参数量下也可能达到相似的执行效率** 
  ，这意味着我们可能已靠近在特定计算资源下函数逼近的极限。
* **语言模型的潜在局限与挑战**
  :
  [@bindureddy](https://twitter.com/bindureddy/status/1784698453802545318?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend) 
  论述
  **语言模型可能将因人类语言和推理的固有限制而在某些基准测试上达到瓶颈** 
  ，尽管增加了计算和数据资源，如MMLU所示。


**视觉-语言模型与视频理解领域的最新进展**


* **PLLaVA: LLaVA 参数自由扩展至视频技术**
 :
 [@\_akhaliq](https://twitter.com/_akhaliq/status/1784752877493203416?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend) 
 介绍了 PLLaVA，这是一种扩展至**视频详细描述任务的 LLaVA 框架，无需依赖大量配对数据**。
 该方法通过使用预训练的二维扩散模型和池化策略，在视频问答和视频描述任务中取得了领先的性能。
* **HaLo-NeRF：学习几何引导下的语义**
 :
 [@\_akhaliq](https://twitter.com/_akhaliq/status/1784755121496224210?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend) 
 展示了 HaLo-NeRF，这是一个系统，它**利用文本描述与地标场景的神经网络表示相结合，实现对语义区域的精细理解及定位**。
 这种方法通过为三维兼容的分割和体积场景表示调整视觉和语言模型来实现。


**大语言模型（LLM）的高效训练与部署技术**


* **FP6量化：提高大语言模型(LLM)推理效率**
  :
  [@rohanpaul_ai](https://twitter.com/rohanpaul_ai/status/1784599257384727044?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)
  分享了一篇利用**六位量化(FP6)在缩减大语言模型的体积的同时保持模型质量**的研究论文。
  论文中提出了一个新的GPU内核设计方案TC-FPx，该方案支持浮点权重的不同量化位宽，有效提升了大语言模型推理的实际性能。
* **代理调整：大型语言模型的高效定制**
  :
  [@rohanpaul_ai](https://twitter.com/rohanpaul_ai/status/1784559710978404861?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)
  解释了代理调整，这是一种**利用较小调试模型调整大型语言模型预测的轻量级解码时间算法**。
  此方法通过解码时的指导，高效地定制大型及潜在的专有语言模型。
* **参数高效的稀疏性打造：针对指令调整**
  :
  [@rohanpaul_ai](https://twitter.com/rohanpaul_ai/status/1784999595413504342?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)
  讨论了一篇提出参数高效的稀疏性打造(PESC)的论文，通过这种方法**将密集模型转化为适用于高效指令调整的稀疏型专家组模型(Mixture-of-Experts，MoE)**。
  在每一位专家中添入适配器并仅更新适配器的参数，显著减少了计算成本和内存需求，实现了最先进的性能。


**法规与政策**


* **加利福尼亚法案1047详细介绍**
   : [@nearcyan](https://twitter.com/nearcyan/status/1784864119491100784?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend) 分享了被快速推进的加利福尼亚法案1047的具体内容。该法案**适用于所有具有10^26 浮点运算次数（FLOPS）或相似性能的模型**，要求开发者在可能面临伪证罪的法律风险下证明模型的安全性，并建立前沿模型监管机构进行汇报。
* **对加利福尼亚SB-1047的关切**
   : [@jeremyphoward](https://twitter.com/jeremyphoward/status/1784717268368367665?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend) 表达了对加利福尼亚SB-1047《前沿人工智能模型安全与创新法案》可能**对初创企业、美国的创新、开源项目及安全性造成重大影响**的担忧。法案中对一些概念定义过于泛泛，对双重用途的理解存在偏差，并设定了诸多限制性要求，这些都可能抑制技术的开放性和透明度。





AI Discord 回顾
================


> 摘要汇总


**1. 大语言模型和人工智能能力的进展**


**[Llama 3](https://huggingface.co/gradientai/Llama-3-8B-Instruct-262k?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)**
目前已经升级，支持高达**[100万Token的上下文窗口](https://x.com/markatgradient/status/1785032103429865748?s=46&t=90xQ8sGy63D2OtiaoGJuww&utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)**，这一进展显著提升了处理长序列的能力。相关教程指导如何将**[检索增强生成（Retrieval-Augmented Generation, RAG）](https://www.youtube.com/watch?v=oDGzMF8CiQU&utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)**技术与Llama 3结合使用，并通过Langchain和Groq技术实现与**[网页浏览功能](https://www.youtube.com/watch?v=au6WQVEgGQo&utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)**的整合。


* **[Microsoft的Phi-3](https://x.com/lmsysorg/status/1783959458005279091?s=46&utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)**，作为下一代快速而强大的模型，自公开发布后已斩获超过6000票，位居榜首。讨论专注于 **[tokenizer的变更](https://huggingface.co/vonjack/Phi-3-mini-4k-instruct-LLaMAfied/discussions/7?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)**，这些变化旨在LlaMa化版本中用于提升聊天应用的表现。


* **[Snowflake Arctic](https://www.youtube.com/watch?v=nV6eIjnHEH0&utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)**
，作为一款企业级大语言模型（LLM），致力于为企业提供高成本效益的 AI 解决方案，积极推进企业 AI 的广泛应用。


**2. 模型优化、量化与提高效率的技巧**


* 针对 **量化技术** 展开了广泛的讨论，特别是关于 **[4bit lora 和 4bit qlora](https://x.com/rohanpaul_ai/status/1784972618472317180?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)**，论及这些技术在不同训练程度下对模型性能的影响。对 **[二进制量化](https://github.com/carsonpo/haystackdb?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)** 的研究旨在开发较小的索引，以优化相似性搜索的效率。


* **[DeepSpeed的FP6量化](https://github.com/microsoft/DeepSpeed/commit/ccfdb84e2a4a373ac657a99afd2d97e1d741b22b?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)**
承诺在保持相似吞吐量（每秒处理的数据量）的基础上进行量化推理，这一进步引发了对效率提升的广泛期待。


* 研究者们展出了专为CPU优化的大语言模型（LLMs），这些模型能够利用连锁思考法 (Chain-of-Thought) 的提示策略[生成 Python 代码](https://arxiv.org/abs/2404.11160)。此举突显了他们对于打造既高效又低成本模型的不懈追求。


**3. 开源AI的开发和社群合作**


* **[Eleuther社区](https://discord.com/channels/729741769192767510/747850033994662000/1233393133937492041?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)** 对大语言模型（LLM）的性能进行比较，探讨其新兴能力，并分享了如冗余神经回路和对大语言模型的对抗性引导等主题的研究。


* **[OpenAccess AI Collective](https://discord.com/channels/1104757954588196865/1104757955204743201/1233372786274074734?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)** 的成员深入研究了微调策略、量化技术以及Token处理的困难，他们还从 **[axolotl](https://github.com/OpenAccess-AI-Collective/axolotl?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)** 和 **[FastChat](https://github.com/lm-sys/FastChat?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)** 等项目中分享了各自的洞见。


* **[LlamaIndex](https://discord.com/channels/1059199217496772688/1059201661417037995/1233371418675380244?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)** 社区正在研究多元技术，包括**多跳检索 (multi-hop retrieval)** 和应用于长期记忆的**知识图谱 (knowledge graphs)**，同时也分享了诸如有关大语言模型 (LLM) 应用开发模式的 **[AWS 工作坊](https://twitter.com/llama_index/status/1783877951278432733?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)** 等资源。


**4. 人工智能开发中的伦理担忧与监管挑战**


* **[LAION](https://discord.com/channels/823813159592001537/823813160075132991/1233337464169431121?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)**
 由于欧盟法律的约束，访问公共计算资源受限，促使研究者转向那些进行活跃实验的社区。


* 围绕提出的 [加利福尼亚SB-1047法案](https://x.com/jeremyphoward/status/1784717268368367665?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend) 的讨论，这个法案可能对初创企业、开源AI（Artificial Intelligence）开发及美国创新构成威胁，突显了监管上的挑战。


**5. 杂项**


* **CUDA C++ 成为焦点**
 : 一场发布在
 [YouTube 的讲座](https://youtu.be/WiB_3Csfj_Q?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)
 探讨了 **CUDA C++ llm.cpp** 对大语言模型 (LLM) 训练的优化，许诺能带来更清晰、更快速的代码。相关的支持材料和讨论显示，这将显著提升性能，并已做好准备将大语言模型扩展到 gpt-large 的规模。


**Intel 的 oneAPI 技术迈出重要步伐**  
: Intel 的 oneAPI 因其提供一个能跨 CPU、GPU 以及 FPGA 的统一编程模型而受到广泛关注。随着 Battlemage GPU 系列的即将发布，人们对此表现出极大的热情。oneAPI 生态系统不断扩大，它通过 [GitHub](https://github.com/oneapi-src) 和 [Codeplay 的官方新闻发布](https://codeplay.com/portal/press-releases/2022/12/16/codeplay-announces-oneapi-for-nvidia-and-amd-gpu-hardware.html) 欢迎跨厂商的支持与贡献。


* **InstaDeep 招募机器学习工程师**
 : InstaDeep 正积极寻求擅长高性能机器学习、生物 AI 和自定义 CUDA Kernel 的机器学习工程师。他们提供一个富有激励的工作环境，并且面向那些愿意在现实世界中解决问题、产生影响的候选人开放多个职位。感兴趣的申请者可以通过 [InstaDeep 招聘门户](https://www.instadeep.com/job-offer/92900fa3-5501-4506-a63f-cebee958fc6f/?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend) 提交申请。


* **AMD 加剧市场竞争**
 : 针对AMD Instinct MI300X在服务器环境中的应用前景及ROCm目前的状况展开了讨论，相关[产品页面](https://www.amd.com/de/products/accelerators/instinct/mi300/platform.html?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)和租赁信息明显显示出与NVIDIA的竞争关系。ROCm的支持和对比分析显示，AMD致力于提升开发者的使用便利性和性能。


* **Triton 和 PyTorch 持续推进**
 : [unsloth](https://github.com/unslothai/unsloth?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend) 
 和 [attorch](https://github.com/BobMcDear/attorch?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend) 
 两个 GitHub 仓库已成为寻求 Triton 和 PyTorch 集成者的宝贵资源。尽管 flash-attn 2.5.8 与 PyTorch 2.3.0 的兼容性获得认可，社区对于 CUDA tensor 索引的最优技术和 Triton 中 tensor 梯度计算的讨论仍在持续，显示出其追求高效率的决心。


{意译结果}


高层级 Discord 摘要
====================================


[Unsloth AI（Daniel Han）](https://discord.com/channels/1179035537009545276?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend) 在 Discord 上


* **Phi 3集成：Unsloth AI的突破**
 : Unsloth AI已支持**Phi 3**技术，实现了速度提升一倍，内存使用减少一半。爱好者可以访问[Colab notebook](https://colab.research.google.com/drive/1NvkBmkHfucGO3Ve9s1NKZvMNlw5p83ym?usp=sharing&utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)，了解更多详细的操作指南。


* **双语模型掀起热潮**
 : Thermostatic 发布了 **NeuralTranslate\_v0.2\_GGUF**，这是一款英西双语翻译模型。该模型不仅维持了 **Mistral** 的推理能力，还避免了过拟合，可在 [Hugging Face](https://huggingface.co/Thermostatic/NeuralTranslate_v0.2_GGUF?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend) 上进行访问。


* **GPU优化讨论**
 : AI社区就如何最小化VRAM消耗进行了广泛的最佳实践讨论，分享了关于手动层剪枝的深入见解，并且在讨论数据卸载技术时引用了[Kolibrify的GitHub仓库](https://github.com/oKatanaaa/kolibrify/blob/7165ebbbcc8c44a6960ccfe78aa2d740a93789bd/kolibrify/model_utils.py?utm_source=ainews&utm_medium=email&utm_campaign=ainews-a-quiet-weekend)中的代码示例。

